version: "3.9"

services:

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.12.1
    ports:
      - "5000:5000"
    command: >
      mlflow server
      --backend-store-uri sqlite:///mlflow.db
      --default-artifact-root /mlruns
      --host 0.0.0.0
    volumes:
      - mlflow_data:/mlruns
      - mlflow_db:/mlflow

  trainer:
    build:
      context: .
      dockerfile: Dockerfile.train
    depends_on:
      - mlflow
    volumes:
      - mlflow_data:/mlruns
    restart: "no"

  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    ports:
      - "8000:8000"
    depends_on:
      - mlflow
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - mlflow_data:/mlruns

  streamlit:
    image: python:3.10
    working_dir: /app
    volumes:
      - ./streamlit:/app
    command: streamlit run app.py
    ports:
      - "8501:8501"
    depends_on:
      - api

  prometheus:
    image: prom/prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    depends_on:
      - prometheus

volumes:
  mlflow_data:
  mlflow_db:
